[TOC]

# CxSpider 长行的爬虫合集

本项目为爬虫合集，主要其一为本合集自行设计实现的爬虫，其二为本合集收录的其他爬虫。

* 自行设计的爬虫
  * 爬虫列表
  * 爬虫的设置&调用方法
  * 工具类说明
  * 免责声明
* 收录的其他爬虫
  * 爬虫列表
  * 爬虫免责说明
* 项目近期计划
* 项目作者介绍

# 自行设计的爬虫

对于本合集自行设计的爬虫，本合集统一了爬虫的配置方式、调用方式和返回结果格式，并遵循如下原则：

1. 每个Python脚本（.py文件）仅依赖于发布在pypi（可以通过pip安装）的工具即自身，方便直接复制代码来使用爬虫。
2. 爬虫返回结果统一为字典列表格式，并在工具类中配有将这种格式写入csv、Excel和MySQL的工具函数。
3. 将所有爬虫发布到pypi的cxspider模块（`pip install cxspider`），方便直接调用。

## 爬虫列表

| ID     | 网站               | 爬虫                               | 爬虫路径                     | 状态   |
| ------ | ------------------ | ---------------------------------- | ---------------------------- | ------ |
| S-01-1 | 微博               | 微博热搜榜实时爬虫                 | weibo.hot_ranking            | 正常   |
| S-02-1 | Twitter            | Twitter用户推文爬虫                | twitter.user_tweet           | 待更新 |
| S-02-2 | Twitter            | Twitter用户信息爬虫                | twitter.user_info            | 正常   |
| S-03-1 | Facebook           | Facebook用户推文爬虫               | facebook.user_tweet          | 正常   |
| V-01-1 | Bilibili           | B站UP主发布视频列表爬虫【Demo】    | bilibili.user_video_list     | 正常   |
| V-02-1 | AcFun              | AcFun视频信息爬虫（包括下载地址）  | acfun.video                  | 正常   |
| G-01-1 | WanPlus-玩加电竞   | 英雄联盟每日比赛列表爬虫           | wanplus.lol_date_list        | 正常   |
| G-01-2 | WanPlus-玩加电竞   | 英雄联盟比赛包含场次列表爬虫       | wanplus.lol_match_list       | 正常   |
| G-01-3 | WanPlus-玩加电竞   | 英雄联盟场次详细信息爬虫           | wanplus.lol_match_info       | 正常   |
| G-02-1 | WeGame(安卓客户端) | 云顶之弈比赛记录爬虫：召唤师列表   | wegame.tft_summoner_list     | 正常   |
| G-02-2 | WeGame(安卓客户端) | 云顶之弈比赛记录爬虫：游戏场次列表 | wegame.tft_exploit_list      | 正常   |
| G-02-3 | WeGame(安卓客户端) | 云顶之弈比赛记录爬虫：游戏场次详情 | wegame.tft_exploit_detail    | 正常   |
| L-01-1 | 虎牙               | 直播弹幕爬虫                       | huya.barrage_of_live         | 正常   |
| L-01-2 | 虎牙               | 直播间订阅数爬虫                   | huya.subscribe_of_live       | 正常   |
| L-02-1 | 斗鱼               | 直播弹幕爬虫                       | douyu.barrage_of_live        | 正常   |
| L-02-2 | 斗鱼               | 直播间订阅数爬虫                   | douyu.subscribe_of_live      | 待修复 |
| L-03-1 | Bilibili           | 直播弹幕爬虫                       | bilibili.barrage_of_live     | 正常   |
| O-01-1 | 安居客             | 安居客各地房源数量爬虫             | anjuke.housing_resources_num | 正常   |
| O-02-1 | 居理新房           | 居理新房城市页面列表爬虫           | julive.city_url_list         | 正常   |
| O-03-1 | 中国知网           | 期刊包含刊期列表爬虫               | cnki.issue_list              | 正常   |
| O-03-4 | 中国知网           | 刊期包含论文列表爬虫               | cnki.article_list            | 正常   |
| O-04-1 | 猫眼               | 猫眼网播热度爬虫【Demo】           | maoyan.web_heat              | 正常   |
| O-05-1 | 豆瓣               | 豆瓣电影TOP250爬虫                 | douban.movie_top_250         | 正常   |
| N-01-1 | 起点中文网         | 小说排行榜                         | novel.qidian_ranking         | 正常   |

##  爬虫设置&调用方法

本合集统一格式的爬虫有三种调用方法：

#### （一）在IDE中执行Python脚本

Step 1：安装爬虫运行所需的环境（安装Python环境+pip安装所需的工具模块+安装Chrome浏览器）

Step 2：将爬虫源代码粘贴到IDE

Step 3：参考Demo实现的爬虫结果数据存储

Step 4：运行爬虫

#### （二）在命令提示符中执行Python脚本

Step 1：安装爬虫运行所需的环境（安装Python环境+pip安装所需的工具模块+安装Chrome浏览器）

Step 2：在命令提示符（CMD）中使用命令行参数设置并运行爬虫

#### （三）使用可执行文件运行（暂未实现）

## 工具类说明

* crawlertool（必须）：本项目配套的最基本的爬虫工具模块，包括爬虫的抽象基类，以及信息提取、数据库读写、IO操作等工具函数（`pip install crawlertool`）
* Selenium4R（Selenium爬虫必须）：本项目配套的Selenium工具模块，魔改版selenium（`pip install Selenium4R`）
* bs4（beautifulsoup4 ）：部分解析dom页面的爬虫所需的工具模块（`pip install bs4`）
* lxml：部分解析dom页面的爬虫所需的工具模块（`pip install lxml`）

> 所有爬虫均会在自己的说明（`README.md`）中注明该爬虫所需的工具模块。

## 免责声明

#### 1\. 免责声明

* 本合集中所有爬虫仅可用于学习、研究用途，不应用于任何商业用途。
* 本合集所有实现和收录的爬虫均只采集公开显示的数据，如公开显示的数据中包含用户个人数据，将依据学习和研究需要模糊处理。
* 使用者如将本合集中的任何爬虫用于商业用途，后果自负！
* 如本合集中的爬虫对您的权益造成了影响，请联系合集作者，本合集将在24小时内移除该爬虫。

#### 2\. 本合集实现爬虫原则

* 严格控制爬虫的请求频率，避免因爬虫导致目标网站的负荷过大。因此，本合集不提供多线程爬虫，同时，在每次请求期间均会留出足够的延时时间。
* 严格控制爬虫仅采集公开的信息。本合集不提供采集被明确标注不希望被他人获取的数据。
* 严格控制爬虫的个人信息获取。爬虫将在抓取环节对于学习、研究无关的个人数据（包括电话、地址、姓名等）进行模糊处理（如记录这些信息的哈希值）。
* 如用户修改或重写爬虫的running方法（即修改或重新设计爬虫），则用户自行设计的爬虫与本合集无关。
* 本合集的的承诺仅对本合集自行实现的爬虫有效，对本合集收录的爬虫，本合集仅作收录，不保证检查其合法性，在使用时，请用户自行衡量并承担其合法性。

# 收录的其他爬虫

对于本合集收录的爬虫，均为发布在Github或博客中的爬虫，本项目作者测试基本无误后收录。本合集将其中的部分爬虫改变为本合集的统一格式，以方便调用，但会明确标注爬虫的来源。

## 爬虫列表

## 免责声明

# 项目近期计划

1. 使用可执行文件运行爬虫的功能
2. 发布CxSpider模块
3. 用于将爬虫抓取结果（字典列表）存储到不同位置的工具函数（包含于crawlertool工具模块中）
4. 近期准备新增的爬虫

# 项目作者介绍

> **长行** 数据挖掘领域懵逼者
>
> LeetCode主页、Github主页、CSDN主页、邮箱

本项目诚邀合作开发者，有意者请联系作者的Github账号或邮箱！

### 打赏项目





