"""
WeGame云顶之弈比赛记录爬虫：游戏场次列表

需要第三方模块：
Utils4R >= 0.0.2

@author: ChangXing
@version: 2.1
@create: 2019.12.10
@revise: 2020.06.09
"""

import os
import time

import crawlertool as tool

import setting


class SpiderTftExploitList(tool.abc.SingleSpider):
    def running(self, summoner, mysql):
        # 设置不需要代理的环境变量(解决request.exceptions.ProxyError:HTTPSConnectionPool的问题)
        os.environ["NO_PROXY"] = "mlol.qt.qq.com"

        # 定义请求信息
        headers = {"Accept-Encoding": "gzip",
                   "Host": "mlol.qt.qq.com",
                   "Connection": "Keep-Alive",
                   "user-agent": "okhttp/3.12.0"}
        cookies = dict(l_uin="o13578660",
                       p_uin="o13578660",
                       uin="o13578660",
                       skey=setting.SKEY)
        params = {
            "user_id": summoner,
            "scene": "tft_mlol",
            "plat": "android",
            "version": "9914",
            "game_area": "1",
            "login_account_type": "1"
        }

        total_num = 0  # 抓取总数

        next_baton = None

        # 执行请求
        for i in range(100):

            print("执行第", i + 1, "次请求...")

            if next_baton:
                params["baton"] = next_baton

            # print(params)

            # 请求召唤师比赛记录列表(需要cookies,p_skey可以不需要,可以使用bacon参数控制翻页)
            response = tool.do_request(
                url="https://mlol.qt.qq.com/gorpc/exploit/exploit/query_player_exploit_list/proxy",
                params=params,
                headers=headers,
                cookies=cookies,
                verify=False)
            exploit_json = response.json()

            # print(json.dumps(exploit_json, ensure_ascii=False))

            if "info" not in exploit_json:
                return total_num
            if "exploit_list" not in exploit_json["info"]:
                return total_num
            if "next_baton" not in exploit_json["info"]:
                return total_num
            next_baton = exploit_json["info"]["next_baton"]

            if exploit_json["info"]["exploit_list"] is None:
                return total_num

            exploit_list = list()
            for exploit_item in exploit_json["info"]["exploit_list"]:
                if "exploit_id" not in exploit_item:
                    continue
                if "end_time" not in exploit_item:
                    continue
                if "game_match_type" not in exploit_item:
                    continue
                if "specific_user_exploit" not in exploit_item:
                    continue
                if "user_id" not in exploit_item["specific_user_exploit"]:
                    continue
                if exploit_item["end_time"] < int(time.mktime(time.strptime(setting.TIME_START, setting.TIME_FORMAT))):
                    mysql.insert("exploit_list", exploit_list)
                    return total_num
                if exploit_item["end_time"] < int(time.mktime(time.strptime(setting.TIME_END, setting.TIME_FORMAT))):
                    exploit_list.append({
                        "exploit_id": exploit_item["exploit_id"],
                        "end_time": exploit_item["end_time"],
                        "user_id": exploit_item["specific_user_exploit"]["user_id"],
                        "game_match_type": exploit_item["game_match_type"],
                        "period": setting.PERIOD
                    })
                    total_num += 1

            if len(exploit_list) > 0:
                mysql.insert("exploit_list", exploit_list)
            else:
                return total_num

            time.sleep(2)

        return total_num


def crawler(mysql):
    summoner_list = mysql.select("summoner", ["uuid"], sql_where="WHERE `period`=" + str(setting.PERIOD))
    print("列表数量:", len(summoner_list))

    spider = SpiderTftExploitList()

    num = 1
    for summoner in summoner_list:
        print("抓取召唤师:", num, "/", len(summoner_list))
        num += 1
        if num < 4:
            time.sleep(2)
            continue
        exploit_num = spider.running(summoner, mysql)
        print("召唤师共计抓取:", exploit_num)
        time.sleep(2)


if __name__ == "__main__":
    crawler(tool.db.MySQL(host="", user="", password="", database=""))
